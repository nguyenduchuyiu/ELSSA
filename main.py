import asyncio
import gc
import yaml
from enum import Enum
from typing import Optional
import sys
import os
import yaml 

config = yaml.safe_load(open("config.yaml", "r"))

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "libs")))
 

from src.layer_1_voice_interface.wake_word_handler import WakeWordHandler
from src.layer_1_voice_interface.speech_to_text import SpeechToText
from src.layer_2_agentic_reasoning.llm_runner import LLMRunner
from src.layer_2_agentic_reasoning.context_manager import ContextManager
from src.utils.sound_player import play_wake_chime

if config['tts_engine'] == "openvoice":
    from src.layer_1_voice_interface.text_to_speech import OpenVoiceTTS as TextToSpeech
else:
    from src.layer_1_voice_interface.text_to_speech import CoquiTTS as TextToSpeech

class SystemState(Enum):
    IDLE = "idle"
    ACTIVE = "active"
    SPEAKING = "speaking"
    ACTIVE_LISTENING = "active_listening"


class ELSSAConfig:
    """Configuration management for ELSSA system"""
    
    def __init__(self, config_file: str = 'config.yaml'):
        with open(config_file, 'r') as f:
            self.config = yaml.safe_load(f)
        
        self.wake_audio_path = "assets/audio/elssa_online.wav"
        self.silence_timeout = self.config['silence_timeout']
        self.asr_timeout = self.config['asr_timeout']
        self.max_silence_retries = self.config['max_silence_retries']
        self.context_dir = "data/context"
        self.max_context_length = self.config['max_context_length']


class ELSSASystem:
    """Main ELSSA system class that manages all components and state transitions"""
    
    def __init__(self, config: ELSSAConfig):
        self.config = config
        self.current_state = SystemState.IDLE
        self.state_lock = asyncio.Lock()
        self._interrupt_detected = asyncio.Event()
        
        # Components
        self.wake_handler: Optional[WakeWordHandler] = None
        self.asr: Optional[SpeechToText] = None
        self.tts: Optional[TextToSpeech] = None
        self.llm_runner: Optional[LLMRunner] = None
        
        # Context management
        self.context_manager = ContextManager(
            context_dir=self.config.context_dir,
            max_context_length=self.config.max_context_length
        )
    
    async def cleanup_resources(self):
        """Clean up all system resources"""
        if self.asr:
            try:
                if self.asr.is_running:
                    await self.asr.stop_async()
                self.asr = None
                print("âœ… ASR stopped")
            except Exception as e:
                print(f"âš ï¸ Error stopping ASR: {e}")
                self.asr = None
        
        if self.tts:
            try:
                self.tts.close()
                self.tts = None
                print("âœ… TTS cleaned up")
            except Exception as e:
                print(f"âš ï¸ Error cleaning TTS: {e}")
                self.tts = None

        if self.llm_runner:
            try:
                self.llm_runner.stop_server()
                self.llm_runner = None
                print("âœ… LLM runner stopped")
            except Exception as e:
                print(f"âš ï¸ Error stopping LLM runner: {e}")
                self.llm_runner = None
        
        if self.wake_handler:
            try:
                self.wake_handler.stop()
                self.wake_handler = None
                print("âœ… Wake handler stopped")
            except Exception as e:
                print(f"âš ï¸ Error stopping wake handler: {e}")
                self.wake_handler = None
        
        # End current conversation session
        if self.context_manager:
            try:
                await self.context_manager.end_current_session()
                print("âœ… Context session ended")
            except Exception as e:
                print(f"âš ï¸ Error ending context session: {e}")
        
        gc.collect()
    
    async def transition_to_idle(self):
        """Transition to IDLE state"""
        async with self.state_lock:
            print("ğŸ”„ Transitioning to IDLE state...")
            self.current_state = SystemState.IDLE
            
            await self.cleanup_resources()
            
            # Start wake word detection
            try:
                self.wake_handler = WakeWordHandler()
                self.wake_handler.register_callback(self._on_wake_detected)
                self.wake_handler.start()
                print("ğŸ‘‚ IDLE: Listening for wake word 'alexa'...")
            except Exception as e:
                print(f"âŒ Error starting wake detection: {e}")
    
    async def transition_to_active(self):
        """Transition to ACTIVE state"""
        async with self.state_lock:
            print("ğŸ”„ Transitioning to ACTIVE state...")
            self.current_state = SystemState.ACTIVE
            
            # Stop wake word detection
            if self.wake_handler:
                self.wake_handler.stop()
                self.wake_handler = None
            
            # Initialize components
            self.tts = TextToSpeech()
            print("âœ… TTS initialized")
            
            self.asr = SpeechToText(silence_threshold=self.config.silence_timeout)
            print("âœ… ASR initialized")

            self.llm_runner = LLMRunner()
            self.llm_runner.launch()
            # Reset conversation history for new session
            self.llm_runner.reset_conversation()
            print("âœ… LLM runner initialized")
            
            # Start new conversation session
            session_id = await self.context_manager.start_new_session()
            print(f"ğŸ“ Started conversation session: {session_id}")
                
            # Play wake acknowledgment
            play_wake_chime()
    
    async def transition_to_speaking(self):
        """Transition to SPEAKING state"""
        async with self.state_lock:
            self.current_state = SystemState.SPEAKING

    async def transition_to_active_listening(self):
        """Transition to ACTIVE_LISTENING state"""
        async with self.state_lock:
            print("ğŸ”„ Transitioning to ACTIVE_LISTENING state...")
            self.current_state = SystemState.ACTIVE_LISTENING
            print("ğŸ‘‚ ACTIVE_LISTENING: Ready to listen immediately after interrupt")
    
    def _on_interrupt_detected(self):
        """Callback for interrupt detection"""
        print("âš¡ INTERRUPT DETECTED during TTS!")
        self._interrupt_detected.set()

    async def _on_wake_detected(self):
        """Callback for wake word detection"""
        if self.current_state == SystemState.IDLE:
            print("ğŸ”” Wake word detected!")
            await self.transition_to_active()
            asyncio.create_task(self._active_conversation_loop())

    async def speak_with_interrupt_support(self, text: str) -> bool:
        """
        Speak with interrupt detection support
        Returns True if completed, False if interrupted
        """
        if not self.tts:
            print("âš ï¸ TTS not available")
            return False
        
        await self.transition_to_speaking()
        self._interrupt_detected.clear()
            
        result = await self.tts.speak_async(
            text, 
            play_audio=True,
            interruptible=True,
            interrupt_callback=self._on_interrupt_detected
        )
        
        if result['interrupted']:
            await self.transition_to_active_listening()
            return False
        else:
            async with self.state_lock:
                self.current_state = SystemState.ACTIVE
            return True

    async def _process_user_input_streaming(self, user_text: str) -> bool:
        """
        Process user input with real-time streaming TTS and tool execution
        """
        if not self.llm_runner or not self.tts:
            fallback_response = "Sorry, I'm having trouble processing your request."
            return await self.speak_with_interrupt_support(fallback_response)
        
        # Add user message to context (for session logging)
        await self.context_manager.add_message("user", user_text)
        
        # Get full conversation context and send to LLM
        conversation_context = await self.context_manager.get_conversation_context()
        
        # Use chat_stream generator for real-time response streaming
        try:
            conversation_history = []
            has_spoken = False
            
            for chunk in self.llm_runner.chat_stream(conversation_context):
                # Update conversation history
                conversation_history = chunk.get("conversation_history", [])
                
                chunk_type = chunk.get("type")
                
                if chunk_type == "response":
                    # Speak response immediately
                    response_text = chunk.get("message", "")
                    if response_text:
                        completed = await self.speak_with_interrupt_support(response_text)
                        has_spoken = True
                        
                        if not completed:
                            # Interrupted during speaking
                            print("ğŸ”„ Conversation was interrupted")
                            await self.transition_to_active_listening()
                            return False
                
                elif chunk_type == "tool_start":
                    # Optional: Could speak tool execution notification
                    tool_calls = chunk.get("tool_calls", [])
                    print(f"ğŸ”§ Tool calls: {tool_calls}")
                    # await self.speak_with_interrupt_support("Let me help you with that.")
                    pass
                
                elif chunk_type == "tool_complete":
                    # Optional: Could speak tool completion
                    pass
                
                elif chunk_type == "error":
                    error_msg = chunk.get("message", "An error occurred")
                    print(f"âŒ {error_msg}")
                    fallback_response = "Sorry, I encountered an error processing your request."
                    return await self.speak_with_interrupt_support(fallback_response)
                
                elif chunk_type == "final":
                    print("âœ… Conversation completed")
                    break
            
            # Save all new messages to context manager (skip user message as it's already saved)
            for msg in conversation_history:
                if msg["role"] == "user" and msg["content"] == user_text:
                    continue  # Skip the user message we already added
                await self.context_manager.add_message(msg["role"], msg["content"])
            
            if has_spoken:
                async with self.state_lock:
                    self.current_state = SystemState.ACTIVE
                return True
            else:
                # No response was spoken
                fallback_response = "I'm not sure how to help with that."
                return await self.speak_with_interrupt_support(fallback_response)
                
        except Exception as e:
            print(f"âŒ Error in streaming: {e}")
            fallback_response = "Sorry, I encountered an error processing your request."
            return await self.speak_with_interrupt_support(fallback_response)

    async def _process_user_input(self, user_text: str) -> str:
        """Process user input and generate response (legacy method for non-streaming)"""
        if not self.llm_runner:
            return "Sorry, I'm having trouble processing your request."
        
        # Add user message to context (for session logging)
        await self.context_manager.add_message("user", user_text)
        
        # Use chat_stream generator to collect final response
        try:
            conversation_history = []
            final_response = ""
            
            for chunk in self.llm_runner.chat_stream(user_text):
                conversation_history = chunk.get("conversation_history", [])
                
                chunk_type = chunk.get("type")
                
                if chunk_type == "response":
                    response_text = chunk.get("message", "")
                    if response_text:
                        final_response += response_text
                        print(response_text, end="", flush=True)
                
                elif chunk_type == "error":
                    error_msg = chunk.get("message", "An error occurred")
                    print(f"âŒ {error_msg}")
                    return "Sorry, I encountered an error processing your request."
                
                elif chunk_type == "final":
                    break
            
            # Save all new messages to context manager (skip user message as it's already saved)
            for msg in conversation_history:
                if msg["role"] == "user" and msg["content"] == user_text:
                    continue  # Skip the user message we already added
                await self.context_manager.add_message(msg["role"], msg["content"])
            
            return final_response if final_response else "I'm not sure how to help with that."
            
        except Exception as e:
            print(f"âŒ Error processing input: {e}")
            return "Sorry, I encountered an error processing your request."

    async def _handle_conversation_turn(self) -> tuple[bool, str]:
        """
        Handle a single conversation turn
        Returns (has_input, user_text)
        """
        try:
            self.asr.reset_session()
            
            if not self.asr.is_running:
                self.asr.start()
            
            try:
                silence_detected, _ = await asyncio.wait_for(
                    self.asr.wait_for_silence_or_text_async(timeout=self.config.asr_timeout),
                    timeout=self.config.asr_timeout + 1.0
                )
            except asyncio.TimeoutError:
                silence_detected = False
            
            # Add small delay after silence detection to allow processing remaining audio chunks
            if silence_detected:
                await asyncio.sleep(0.5)  # Wait for any remaining chunks to be processed
            
            # Get final text from stop_async() which includes all processed chunks
            user_text = ""
            if self.asr.is_running:
                user_text = await self.asr.stop_async() 
            
            has_meaningful_input = user_text and len(user_text.strip()) > 0
            return has_meaningful_input, user_text
            
        except Exception as e:
            print(f"âš ï¸ Error in conversation turn: {e}")
            if self.asr and self.asr.is_running:
                await self.asr.stop_async()
            return False, ""

    async def _active_conversation_loop(self):
        """Main conversation loop for ACTIVE state"""
        silence_count = 0
        
        while (self.current_state in [SystemState.ACTIVE, SystemState.ACTIVE_LISTENING] 
               and silence_count < self.config.max_silence_retries):
            
            # Handle state transitions
            if self.current_state == SystemState.ACTIVE_LISTENING:
                print("ğŸ¤ ACTIVE_LISTENING: Listening immediately after interrupt...")
                async with self.state_lock:
                    self.current_state = SystemState.ACTIVE
            elif self.current_state == SystemState.ACTIVE:
                print(f"ğŸ¤ ACTIVE: Listening... (silence count: {silence_count}/{self.config.max_silence_retries})")
            else:
                break
            
            # Handle conversation turn
            has_input, user_text = await self._handle_conversation_turn()
            # has_input = True            
            # user_text = random.choice(qa_test_list)
            
            if has_input:
                silence_count = 0
                print(f"ğŸ“ User said: '{user_text}'")
                
                # Use streaming response directly to TTS
                completed = await self._process_user_input_streaming(user_text)
                if not completed:
                    continue
            else:
                silence_count += 1
                print(f"ğŸ”‡ No input detected. Silence count: {silence_count}/{self.config.max_silence_retries}")
                
                if silence_count == 1:
                    completed = await self.speak_with_interrupt_support("Where did you go?")
                elif silence_count == 2:
                    completed = await self.speak_with_interrupt_support("Still can't hear you!")
                else:
                    break
                
                if not completed:
                    continue
        
        # Exit conversation
        if silence_count >= self.config.max_silence_retries:
            print("ğŸ›‘ Max silence retries reached. Returning to IDLE.")
        else:
            print("ğŸ›‘ Conversation ended. Returning to IDLE.")
        
        await self.transition_to_idle()

    async def start(self):
        """Start the ELSSA system"""
        print("ğŸš€ Starting ELSSA system...")
        await self.transition_to_idle()
        
        try:
            while True:
                await asyncio.sleep(1)
        except KeyboardInterrupt:
            print("\nğŸ›‘ Shutting down...")
            await self.cleanup_resources()
            print("ğŸ‘‹ Goodbye!")
        except Exception as e:
            print(f"ğŸ’¥ Unexpected error: {e}")
            await self.cleanup_resources()


async def main():
    """Main entry point"""
    config = ELSSAConfig()
    system = ELSSASystem(config)
    await system.start()


if __name__ == "__main__":
    asyncio.run(main())
